# Spending Tracker with Persistent Storage

A powerful, full-stack web application for analyzing CSV transaction data with interactive dashboards, charts, and comprehensive filtering capabilities. Now featuring **persistent database storage** for permanent data management and advanced CSV import capabilities.

Built with Next.js, React, TypeScript, SQLite, and modern web technologies.

## ğŸŒŸ Key Features

### ğŸ’¾ **Dual Storage Options**
- **ğŸ—„ï¸ Database Storage**: Persistent SQLite database for permanent data storage
- **ğŸ“ File Storage**: Quick analysis with browser localStorage (legacy mode)
- **ğŸ”„ Seamless Switching**: Toggle between storage modes instantly

### ğŸ“Š **Advanced Import System**
- **ğŸ“ Professional CSV Import**: Dedicated import page with validation and progress tracking
- **ğŸ” Duplicate Detection**: Automatic detection and prevention of duplicate transactions
- **ğŸ“ˆ Smart Validation**: Comprehensive error reporting and data quality checks
- **ğŸ’ª Bulk Processing**: Handle large CSV files (up to 10MB, 10,000+ transactions)

### ğŸ“Š **Interactive Analytics**
- **ğŸ“Š Real-time Dashboard**: Financial KPIs with income, spending, and net amount tracking
- **ğŸ“ˆ Dynamic Charts**: Interactive category breakdowns with pie and bar chart views
- **ğŸ—“ï¸ Spending Calendar**: Visual heatmap of daily spending patterns
- **ğŸ” Advanced Filtering**: Filter by category, merchant, amount range, date range, and text search

### ğŸ› ï¸ **Professional Features**
- **ğŸ“‹ Smart Table**: Sortable, paginated transaction table with advanced search
- **ğŸ’¾ Export Options**: Export filtered data to CSV with comprehensive reporting
- **ğŸ”’ Data Security**: Local SQLite database with no external dependencies
- **ğŸ“± Mobile-Responsive**: Optimized for all devices with touch-friendly interactions
- **âš¡ High Performance**: <2 second load times, handles 10k+ transactions efficiently

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ installed on your system
- A CSV file with transaction data

### Installation & Setup

1. **Clone and Install**:
   ```bash
   git clone <repository-url>
   cd spending-tracker
   npm install
   ```

2. **Start Development Server**:
   ```bash
   npm run dev
   ```

3. **Access Application**:
   Open http://localhost:3000/ in your browser

4. **Database Initialization**:
   The SQLite database automatically initializes on first run at `./data/spending.db`

## ğŸ’¾ Storage Architecture

### Database Storage (Recommended)
- **Persistent Data**: SQLite database stores transactions permanently
- **Advanced Features**: Duplicate detection, data validation, bulk operations
- **Performance**: Optimized with indexes and query optimization
- **Reliability**: ACID compliance with automatic backup capabilities

### File Storage (Legacy)
- **Quick Analysis**: Browser localStorage for temporary analysis
- **No Setup**: Works immediately without database setup
- **Migration Path**: Easy migration to database storage when ready

### Data Source Selection
Use the data source selector in the dashboard header to switch between:
- **ğŸ“ File**: Browser localStorage (temporary)
- **ğŸ—„ï¸ Database**: SQLite database (permanent)

## ğŸ“‹ CSV File Format

Your CSV file must include these **required columns**:

| Column | Description | Format | Example |
|--------|-------------|--------|---------|
| `date` | Transaction date | YYYY-MM-DD, MM/DD/YYYY | 2025-09-15 |
| `amount` | Transaction amount | Decimal number | -89.50 or 2500.00 |
| `description` | Transaction details | Text | "Walmart Supercentre #1234" |

**Optional columns**:
- `category` - Transaction category (e.g., "Groceries", "Dining")
- `merchant` - Merchant name
- `account` - Account name

### Sample CSV Format:
```csv
date,amount,description,category
2025-01-01,-50.00,Grocery Store,Food
2025-01-02,-25.50,Coffee Shop,Dining
2025-01-03,2500.00,Salary,Income
```

## ğŸ¯ New User Journeys

### 1. New User: Database-First Experience

**Goal**: Start with persistent storage and import transaction data

**Steps**:
1. **Open Application** â†’ Visit http://localhost:3000/
2. **Database Auto-Setup** â†’ SQLite database initializes automatically
3. **Import Data** â†’ Click "Import CSV (Recommended)" button
4. **Upload CSV** â†’ Drag-and-drop file or browse to select
5. **Configure Import** â†’ Choose options:
   - Skip duplicate transactions (recommended)
   - Validate only (preview mode)
6. **Review Results** â†’ See detailed import summary:
   - âœ… Imported transactions count
   - âš ï¸ Duplicate transactions detected
   - âŒ Validation errors with row details
7. **Explore Dashboard** â†’ View analytics with database storage indicator

**Expected Results**:
- âœ… Database connection established automatically
- âœ… CSV processed with duplicate detection
- âœ… Comprehensive import reporting
- âœ… Persistent data across browser sessions

---

### 2. Existing User: Migration from File Storage

**Goal**: Migrate existing file data to permanent database storage

**Steps**:
1. **Current State** â†’ Dashboard shows existing file data (e.g., 84 transactions)
2. **Discover Database** â†’ Notice data source selector with "Database" option
3. **Switch to Database** â†’ Select "Database" from dropdown
4. **See Empty State** â†’ Database has no data initially
5. **Export Existing Data** â†’ Use "Export" button to download current data as CSV
6. **Import to Database** â†’ Click "Import CSV" and upload the exported file
7. **Verify Migration** â†’ Confirm all data appears in database mode
8. **Continue with Database** â†’ Use database as primary storage going forward

**Migration Benefits**:
- ğŸ›¡ï¸ Permanent storage (survives browser data clearing)
- ğŸ“Š Advanced duplicate detection
- ğŸ” Better query performance for large datasets
- ğŸ“ˆ Enhanced analytics capabilities

---

### 3. Power User: Dual Storage Workflow

**Goal**: Use both storage modes for different purposes

**Steps**:
1. **Database for Production** â†’ Keep main financial data in database
2. **File for Quick Analysis** â†’ Upload one-off files for temporary analysis
3. **Compare Datasets** â†’ Switch between sources to compare different periods
4. **Export and Share** â†’ Generate reports from either storage source

**Use Cases**:
- Monthly statements in database, yearly analysis in file mode
- Personal data in database, business expenses via file upload
- Historical data in database, current month analysis in file mode

---

### 4. Professional CSV Import Workflow

**Goal**: Import large, complex CSV files with validation

**Steps**:
1. **Navigate to Import** â†’ Click "Import CSV" from dashboard
2. **Review Format Guide** â†’ Check CSV format requirements and examples
3. **Upload Large File** â†’ Drop file up to 10MB (10,000+ transactions)
4. **Preview Data** â†’ See file preview with headers and sample rows
5. **Configure Options**:
   - âœ… Skip duplicates (prevents duplicate imports)
   - âšª Validate only (test run without importing)
6. **Monitor Progress** â†’ Real-time progress bar and status updates
7. **Review Detailed Results**:
   - **Import Summary**: Total rows, imported, duplicates, errors
   - **Imported Transactions**: Preview of successfully imported data
   - **Duplicates Found**: List of duplicate transactions with existing IDs
   - **Validation Errors**: Row-by-row error details with field-specific messages
8. **Export Results** â†’ Download import session results as JSON
9. **Return to Dashboard** â†’ View imported data immediately

**Advanced Features**:
- ğŸ” Row-level error reporting with specific field validation
- ğŸ“Š Statistical summary of import session
- ğŸ’¾ Export import results for record-keeping
- ğŸ”„ One-click option to start new import

---

### 5. Data Analysis and Reporting

**Goal**: Comprehensive financial analysis with persistent data

**Steps**:
1. **Dashboard Overview** â†’ View KPIs with storage status indicator
2. **Storage Status** â†’ Monitor database connection and transaction count
3. **Interactive Filtering**:
   - ğŸ—“ï¸ Date range selection
   - ğŸ’° Amount range filtering
   - ğŸ·ï¸ Category and merchant filtering
   - ğŸ” Text search across descriptions
4. **Visual Analytics**:
   - ğŸ“Š Category breakdown charts
   - ğŸ—“ï¸ Spending calendar heatmap
   - ğŸ“ˆ Trend analysis over time
5. **Data Export** â†’ Export filtered results for external analysis
6. **Session Persistence** â†’ All data and filters saved automatically

---

### 6. Error Handling and Troubleshooting

**Goal**: Handle common issues gracefully

**Common Scenarios**:

**Database Connection Issues**:
- **Indicator**: Red status dot in storage status card
- **Solution**: Database auto-reconnects on next page load
- **Fallback**: Switch to file storage for immediate analysis

**CSV Import Errors**:
- **Missing Columns**: Clear error message with required format
- **Invalid Dates**: Row-specific error reporting
- **Large Files**: Progress indicator prevents timeout confusion
- **Duplicates**: Transparent reporting with existing transaction IDs

**Performance Issues**:
- **Large Datasets**: Automatic pagination and virtualization
- **Memory Management**: Efficient data processing with cleanup
- **Browser Compatibility**: Graceful degradation for older browsers

## ğŸ›  Advanced Configuration

### Database Setup

**Automatic Initialization**:
```javascript
// Database auto-configures on first run
- Location: ./data/spending.db
- Schema: Auto-migrated to latest version
- Optimization: WAL mode for better performance
- Backup: Manual backup recommended for production
```

**Manual Database Management**:
```bash
# View database info
npm run db:status

# Manual migration (if needed)
npm run db:migrate

# Create backup
cp ./data/spending.db ./data/spending-backup.db
```

### Performance Tuning

**For Large Datasets (10k+ transactions)**:
- Database storage recommended over file storage
- Enable browser hardware acceleration
- Consider database cleanup for old data

**Memory Optimization**:
- Import large files in database mode
- Use filters to reduce displayed data
- Clear browser cache periodically

## ğŸ”§ API Documentation

### Storage Status Endpoint
```
GET /api/storage/status
Response: {
  connected: boolean,
  transactionCount: number,
  databaseSize: number,
  version: string
}
```

### Transaction Import Endpoint
```
POST /api/transactions/import
Body: FormData with 'file' and 'options'
Response: {
  session: ImportSession,
  imported: Transaction[],
  duplicates: DuplicateInfo[],
  errors: ValidationError[]
}
```

### Transactions API
```
GET /api/transactions?page=1&limit=100&category=Food
Response: {
  transactions: Transaction[],
  pagination: PaginationInfo
}
```

## ğŸ”’ Privacy & Security

- **Local Database**: SQLite database stored locally, no external connections
- **No Data Transmission**: All processing happens on your machine
- **Offline Capable**: Full functionality without internet connection
- **Data Ownership**: Complete control over your financial data
- **No Tracking**: Zero analytics or user behavior tracking

## ğŸš¨ Troubleshooting

### Database Issues

**Database Connection Failed**:
1. Check file permissions in `./data/` directory
2. Restart application (`npm run dev`)
3. Check disk space availability
4. Fallback to file storage if needed

**Import Errors**:
1. Verify CSV format matches requirements
2. Check file size (<10MB limit)
3. Review error details in import results
4. Try validation-only mode first

**Performance Issues**:
1. Switch to database storage for large datasets
2. Use filters to reduce data display
3. Close unnecessary browser tabs
4. Clear browser cache and reload

### Migration Issues

**File to Database Migration**:
1. Export current file data to CSV
2. Switch to database mode
3. Import the exported CSV file
4. Verify data integrity
5. Continue using database storage

## ğŸ“ Support

**For Technical Issues**:
1. Check browser console for error messages
2. Verify CSV format with provided examples
3. Test database connection via storage status
4. Try file storage as fallback option

**For Feature Requests**:
- Database storage enhancements
- Additional import formats
- Advanced analytics features
- Export format options

---

## ğŸ— Technical Architecture

**Frontend**: Next.js 14+ with React 18+ and TypeScript
**Database**: SQLite with better-sqlite3 driver
**Import Processing**: Streaming CSV parser with validation
**Storage Layer**: Repository pattern with service abstraction
**API**: RESTful endpoints with comprehensive error handling
**UI Components**: Tailwind CSS with Radix UI and shadcn/ui

**Performance Targets**:
- Dashboard load: <2 seconds
- CSV import: <5 seconds for 10k transactions
- Database operations: <100ms average
- Memory usage: <512MB for large datasets

---

**Ready to manage your finances with persistent storage? Import your CSV data and start building your financial insights! ğŸ“ŠğŸ’°**